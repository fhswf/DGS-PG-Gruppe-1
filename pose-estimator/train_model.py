"""
ğŸ“ Training-Skript fÃ¼r das 3D Pose Estimation Modell
ANGEPASST FÃœR IHRE DATEN

Dieses Skript trainiert ein neuronales Netz, das aus 2D-Posen (z.B. von OpenPose)
3D-Posen rekonstruiert. Es verwendet einen zweistufigen Trainingsansatz.
"""

from pose_estimator_3d import train_new_model
from pathlib import Path
import sys

# ===============================================
# VISUELLE TRENNUNG IN DER KONSOLE
# ===============================================
print("=" * 80)
print("ğŸ“ TRAINING: 3D Pose Estimation Modell")
print("=" * 80)
print()

# ===============================================
# âš™ï¸ KONFIGURATION - ANGEPASST FÃœR IHRE DATEIEN
# ===============================================

# ğŸ“ OPTION B: Mehrere Dateien (inkrementelles Training)
# Diese Variable steuert, ob eine einzelne Datei oder mehrere Dateien verwendet werden
SINGLE_FILE_MODE = False  # Wichtig: Auf False setzen fÃ¼r inkrementelles Training!

# Ihre Trainingsdateien - Liste der JSON-Dateien, die die Trainingsdaten enthalten
# Jede Datei enthÃ¤lt 2Dâ†’3D Pose-Paare fÃ¼r das Training
TRAIN_DATA = [
    '2Dto3D_train_part1.json',  # Teil 1 des Datasets
    '2Dto3D_train_part2.json',  # Teil 2 des Datasets
    '2Dto3D_train_part3.json',  # Teil 3 des Datasets
    '2Dto3D_train_part4.json',  # Teil 4 des Datasets
    '2Dto3D_train_part5.json'   # Teil 5 des Datasets
]

# Hauptdatei fÃ¼r Final-Training - EnthÃ¤lt alle Daten kombiniert
MAIN_TRAIN_DATA = '2Dto3D_train.json'

# Testdaten - Wird auf None gesetzt, da automatisch gesplittet wird
TEST_DATA = None  # Das Skript teilt automatisch 20% der Daten fÃ¼r Tests ab

# ğŸ¯ Training-Parameter
OUTPUT_MODEL = 'lifting2DTo3D.pth'  # Dateiname des trainierten Modells
EPOCHS = 75                          # Anzahl der TrainingsdurchlÃ¤ufe pro Phase
LEARNING_RATE = 0.002               # Schrittweite der Gradientenabstiegsoptimierung
BATCH_SIZE = 128                    # Anzahl der Samples pro Optimierungsschritt

# ===============================================
# ğŸ” PRE-FLIGHT CHECK - DATEIEXISTENZ PRÃœFEN
# ===============================================
print("ğŸ” ÃœberprÃ¼fe Dateien...")

def check_file(path):
    """
    PrÃ¼ft, ob eine Datei oder Liste von Dateien existiert
    
    Args:
        path: String mit Dateipfad oder Liste von Dateipfaden
    
    Returns:
        bool: True wenn alle Dateien existieren, sonst False
    """
    if isinstance(path, list):
        # PrÃ¼fe jede Datei in der Liste
        for p in path:
            if not Path(p).exists():
                print(f"âŒ Datei nicht gefunden: {p}")
                return False
        return True
    else:
        # PrÃ¼fe einzelne Datei (nur wenn nicht None)
        if path and not Path(path).exists():
            print(f"âŒ Datei nicht gefunden: {path}")
            return False
        return True

# Kopiere die Trainingsdatenliste und fÃ¼ge die Hauptdatei hinzu
all_files = TRAIN_DATA.copy()
all_files.append(MAIN_TRAIN_DATA)

# PrÃ¼fe ob alle benÃ¶tigten Dateien existieren
if not check_file(all_files):
    print("\nâš ï¸  FEHLER: Training-Daten nicht gefunden!")
    print("   Stelle sicher, dass alle JSON-Dateien im aktuellen Verzeichnis sind")
    print("   Aktuelles Verzeichnis:", Path.cwd())
    exit(1)  # Beende das Skript mit Fehlercode 1

print("âœ… Alle Dateien gefunden!")

# ===============================================
# ğŸ“Š KONFIGURATION ANZEIGEN
# ===============================================
print("\n" + "="*80)
print("ğŸ“‹ TRAINING-KONFIGURATION")
print("="*80)

# ErklÃ¤re den zweistufigen Trainingsansatz
print("ğŸ“ Training in zwei Phasen:")
print("   1. Inkrementelles Training auf 5 Teilen")
print("   2. Final-Training auf vollstÃ¤ndigem Dataset")

print(f"\nğŸ“ Inkrementelle Dateien ({len(TRAIN_DATA)} Teile):")
for i, f in enumerate(TRAIN_DATA, 1):
    print(f"   {i}. {f}")

print(f"\nğŸ“ Final-Training Datei: {MAIN_TRAIN_DATA}")
print(f"ğŸ“Š Split: 80% Training / 20% Test (automatisch)")

print(f"\nâš™ï¸  Parameter:")
print(f"   ğŸ¯ Epochen pro Teil: {EPOCHS}")
print(f"   ğŸ“¦ Batch-GrÃ¶ÃŸe: {BATCH_SIZE}")
print(f"   ğŸ“ˆ Lernrate: {LEARNING_RATE}")
print(f"   ğŸ’¾ Output: {OUTPUT_MODEL}")

# ===============================================
# ğŸš€ TRAINING-PROZESS STARTEN
# ===============================================
print("\n" + "="*80)
print("ğŸš€ STARTE TRAINING")
print("="*80)
print("\nğŸ’¡ HINWEIS: Das Training erfolgt in zwei Phasen...")
print()

# Warte auf BenutzerbestÃ¤tigung bevor das Training startet
input("DrÃ¼cke ENTER zum Starten oder STRG+C zum Abbrechen...")

try:
    # ===============================================
    # ğŸ“¦ PHASE 1: INKREMENTELLES TRAINING AUF TEILEN
    # ===============================================
    print("\n" + "="*60)
    print("ğŸ“¦ PHASE 1: Inkrementelles Training auf 5 Teilen")
    print("="*60)
    
    print("ğŸ¤– Initialisiere Modell...")
    
    # Importiere die Funktion fÃ¼r inkrementelles Training
    from pose_estimator_3d import train_on_h3wb_incremental
    
    # Starte das inkrementelle Training
    model = train_on_h3wb_incremental(
        train_json_files=TRAIN_DATA,  # Liste der Teil-Datasets
        test_json=None,               # Automatischer Split aus Trainingsdaten
        epochs=EPOCHS,                # Epochen pro Teil-Dataset
        batch_size=BATCH_SIZE,        # Batch-GrÃ¶ÃŸe
        learning_rate=LEARNING_RATE,  # AnfÃ¤ngliche Lernrate
        output_model=OUTPUT_MODEL,    # Wo das Modell gespeichert wird
        train_split=0.8,              # 80% Training, 20% Test
        checkpoint_interval=10        # Speichert Modell alle 10 Epochen
    )
    
    print("âœ… Phase 1 abgeschlossen!")
    
    # ===============================================
    # ğŸ† PHASE 2: FINAL-TRAINING AUF VOLLEM DATASET
    # ===============================================
    print("\n" + "="*60)
    print("ğŸ† PHASE 2: Final-Training auf vollstÃ¤ndigem Dataset")
    print("="*60)
    
    # Importiere die Funktion fÃ¼r Final-Training
    from pose_estimator_3d import train_on_h3wb
    
    print(f"ğŸ“‚ Verwende vollstÃ¤ndiges Dataset: {MAIN_TRAIN_DATA}")
    
    # Finales Training mit reduzierter Lernrate fÃ¼r Feintuning
    model = train_on_h3wb(
        train_json=MAIN_TRAIN_DATA,       # VollstÃ¤ndiges Dataset
        test_json=None,                   # Automatischer Split
        epochs=EPOCHS,                    # Weitere Epochen
        batch_size=BATCH_SIZE,            # Gleiche Batch-GrÃ¶ÃŸe
        learning_rate=LEARNING_RATE * 0.5,# Reduzierte Lernrate fÃ¼r Feintuning
        output_model=OUTPUT_MODEL,        # Ãœberschreibt das vorherige Modell
        train_split=0.8                   # 80% Training, 20% Test
    )
    
    # ===============================================
    # ğŸ‰ TRAINING ERFOLGREICH ABGESCHLOSSEN
    # ===============================================
    print("\n" + "="*80)
    print("ğŸ‰ TRAINING ERFOLGREICH ABGESCHLOSSEN!")
    print("="*80)
    print(f"\nâœ… Trainiertes Modell gespeichert: {OUTPUT_MODEL}")
    print(f"\nğŸ“Š Zusammenfassung:")
    print(f"   ğŸ“ {len(TRAIN_DATA)} Teil-Datasets verarbeitet")
    print(f"   ğŸ“Š VollstÃ¤ndiges Dataset: {MAIN_TRAIN_DATA}")
    print(f"   â±ï¸  Gesamt-Epochen: {EPOCHS * (len(TRAIN_DATA) + 1)}")
    print(f"\nğŸš€ NÃ¤chste Schritte:")
    print(f"   1. Teste das Modell: python rtmtest.py")
    print(f"   2. ÃœberprÃ¼fe die Ergebnisse in poses_3d_mlp.json")
    print(f"   3. Vergleiche mit geometric Methode")
    
# ===============================================
# ğŸ›‘ FEHLERBEHANDLUNG
# ===============================================
except KeyboardInterrupt:
    # Wird aufgerufen wenn der Benutzer STRG+C drÃ¼ckt
    print("\n\nâš ï¸  Training abgebrochen!")
    print("   Checkpoints wurden gespeichert und kÃ¶nnen fortgesetzt werden")
    
except Exception as e:
    # Allgemeine Fehlerbehandlung fÃ¼r unerwartete Fehler
    print(f"\n\nâŒ FEHLER beim Training:")
    print(f"   {str(e)}")
    
    # Zeige detaillierten Stack-Trace fÃ¼r Debugging
    import traceback
    traceback.print_exc()
    
    # Gebe dem Benutzer hilfreiche LÃ¶sungsvorschlÃ¤ge
    print("\nğŸ”§ MÃ¶gliche LÃ¶sungen:")
    print("   - Reduziere BATCH_SIZE weiter (z.B. auf 64)")
    print("   - Stelle sicher, dass JSON-Dateien korrektes Format haben")
    print("   - PrÃ¼fe ob genug RAM/VRAM vorhanden ist")

# ===============================================
# ENDE DES SKRIPTS
# ===============================================
print("\n" + "="*80)