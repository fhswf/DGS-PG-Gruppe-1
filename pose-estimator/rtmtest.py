"""
ğŸ”„ Aktualisiertes Test-Skript fÃ¼r die komplette 2Dâ†’3D Pipeline

EINFACHE ERKLÃ„RUNG:
Dies ist unser "Hauptprogramm", das alle Teile zusammenfÃ¼gt wie ein Rezept:
1. ğŸ–¼ï¸  Nimm ein Bild
2. ğŸ¤–  Finde Menschen darin (2D)
3. ğŸ”„  Mache es 3D-fÃ¤hig
4. ğŸ¨  Zeichne und zeige das Ergebnis

So wie ein KÃ¼chenrezept: Zutaten â†’ Schritte â†’ fertiges Gericht!
"""

# ===============================================
# ğŸ“¦ IMPORTIEREN DER EIGENEN MODULE
# ===============================================
# Hier laden wir unsere selbstgeschriebenen "WerkzeugkÃ¤sten"
from pose_estimator_2d import PoseEstimator2D, DEFAULT_IGNORE_KEYPOINTS, filter_keypoints
from pose_estimator_3d import convert_2d_poses_to_3d  # ğŸ”„ Neues 3D-Modul
from pose_3d_visualizer_updated import plot_3d_pose_from_json, plot_multiple_views  # ğŸ¨ Verbesserter Visualizer
import json  # ğŸ“„ Zum Lesen/Schreiben von Daten-Dateien
import numpy as np  # ğŸ”¢ FÃ¼r Mathe-Berechnungen

# ===============================================
# ğŸš€ WILLKOMMENSNACHRICHT
# ===============================================
print("=" * 80)
print("ğŸ¯ TEST: Komplette 2D â†’ 3D KÃ¶rperpositions-Pipeline")
print("=" * 80)
print("ğŸ“‹ Dieses Programm fÃ¼hrt alle Schritte automatisch durch:")
print("   1. ğŸ–¼ï¸  Finde Menschen im Bild (2D)")
print("   2. ğŸ”„  Mache 3D-Modelle daraus")
print("   3. ğŸ¨  Zeichne und zeige die Ergebnisse")
print("=" * 80)

# ===============================================
# ğŸ–¼ï¸ SCHRITT 0: BILD AUSWÃ„HLEN
# ===============================================
print("\nğŸ“¸ SCHRITT 0: WÃ¤hle ein Testbild aus")

# ğŸ–¼ï¸ Liste der verfÃ¼gbaren Testbilder (nur eins aktiv lassen!)
file = "V.png"        # ğŸŸ¦ Beispielbild 1 - Person mit V-Hand
#file = "hocke.jpg"    # ğŸŸ¦ Beispielbild 2 - Person in der Hocke
#file = "mensch.jpg"   # ğŸŸ¦ Beispielbild 3 - Standard-Person
#file = "merkel.jpg"   # ğŸŸ¦ Beispielbild 4 - Angela Merkel
#file = "merz.jpg"     # ğŸŸ¦ Beispielbild 5 - Friedrich Merz

print(f"âœ… AusgewÃ¤hltes Bild: {file}")
print("   â„¹ï¸  Um ein anderes Bild zu testen, Ã¤ndere Zeile 31-35")

# ===============================================
# ğŸ¯ SCHRITT 1: 2D-KÃ–RPERPOSITIONEN FINDEN
# ===============================================
print("\n" + "="*80)
print("ğŸ“¸ SCHRITT 1: Finde Menschen im Bild (2D)")
print("="*80)
print("ğŸ¤– Die KI schaut sich das Bild an und sagt:")
print('   "Hier ist ein Mensch, hier sind seine KÃ¶rperteile!"')

# ğŸš« Welche KÃ¶rperteile werden ignoriert? (Beine/FÃ¼ÃŸe)
print(f"ğŸš« Ignoriere Punkte: {DEFAULT_IGNORE_KEYPOINTS} (Beine/FÃ¼ÃŸe)")
print("   Warum? Manchmal wollen wir uns nur auf den OberkÃ¶rper konzentrieren.")

# ğŸ¤– Erstelle den 2D-"Body-Detektor"
estimator_2d = PoseEstimator2D(kpt_threshold=0.9)  # ğŸ¯ 90% Mindest-Genauigkeit
print("âœ… 2D-Pose-Estimator erstellt (sehr hohe Genauigkeit)")

# ğŸ¯ Bild analysieren (KI-Magie passiert hier!)
result_2d = estimator_2d.process_image(file)
print(f"ğŸ‘¤ Gefunden: {result_2d.num_persons} Person(en) im Bild")

# ğŸ” Zeige was die KI gemacht hat (fÃ¼r Entwickler)
if result_2d.num_persons > 0:
    print("\nğŸ” KI-Ersetzungen (automatisch korrigiert):")
    print(f"   ğŸ‘ƒ Nase (Punkt 0):  Wurde durch Punkt 53 (Gesichts-Nase) ersetzt")
    print(f"   âœ‹ Linkes Handgelenk: Punkt 9 â†’ Punkt 91 (genauer)")
    print(f"   âœ‹ Rechtes Handgelenk: Punkt 10 â†’ Punkt 112 (genauer)")

# ğŸš« Filtere Beine heraus (machen sie "unsichtbar")
print(f"\nğŸš« Filtere Beine/FÃ¼ÃŸe (Punkte 13-22) aus...")
result_2d.keypoints, result_2d.scores = filter_keypoints(
    result_2d.keypoints,      # ğŸ“ Original-Punkte
    result_2d.scores,         # ğŸ¯ Original-Genauigkeiten
    DEFAULT_IGNORE_KEYPOINTS  # ğŸš« Welche Punkte ignorieren?
)

# âœ… ÃœberprÃ¼fe ob Filterung funktioniert hat
if result_2d.num_persons > 0:
    filtered_scores = result_2d.scores[0][DEFAULT_IGNORE_KEYPOINTS]
    filtered_count = np.sum(filtered_scores == 0)  # ğŸ¯ Wie viele sind jetzt 0?
    print(f"âœ… {filtered_count} Bein-Punkte wurden 'unsichtbar' gemacht")

# ===============================================
# ğŸ’¾ SCHRITT 2: 2D-DATEN SPEICHERN (fÃ¼r 3D)
# ===============================================
print("\nğŸ’¾ Speichere 2D-Daten fÃ¼r 3D-Konvertierung...")

# ğŸ“‹ Erstelle spezielles Format (linke & rechte "Kamera")
results_2d_list = [{
    "frame": 0,  # ğŸï¸ Bild-Nummer (0 fÃ¼r einzelnes Bild)
    "left": {    # ğŸ‘ˆ Linke "Kamera"-Ansicht
        "num_persons": result_2d.num_persons,
        "keypoints": result_2d.keypoints.tolist(),  # ğŸ”„ In Liste umwandeln
        "scores": result_2d.scores.tolist(),
        "bboxes": result_2d.bboxes.tolist()
    },
    "right": {   # ğŸ‘‰ Rechte "Kamera"-Ansicht (bei Einzelbild: Kopie)
        "num_persons": result_2d.num_persons,
        "keypoints": result_2d.keypoints.tolist(),
        "scores": result_2d.scores.tolist(),
        "bboxes": result_2d.bboxes.tolist()
    }
}]

# ğŸ“ In Datei speichern
with open("poses_2d_filtered.json", "w") as f:
    json.dump(results_2d_list, f, indent=2)  # ğŸ“ SchÃ¶n formatiert
print("âœ… Gespeichert: poses_2d_filtered.json")

# ===============================================
# ğŸ–ï¸ SCHRITT 3: 2D-BILD ANNOTIEREN (zeichnen)
# ===============================================
print("\n" + "="*80)
print("ğŸ–ï¸ SCHRITT 3: Zeichne KÃ¶rperlinien auf das Originalbild")
print("="*80)
print("ğŸ¨ Jetzt malen wir die gefundenen Menschen ein:")
print("   - ğŸŸ© GrÃ¼ne Linien fÃ¼r KÃ¶rperverbindungen")
print("   - ğŸ”´ Rote Punkte fÃ¼r KÃ¶rperpositionen")
print("   - ğŸš« KEINE Bein-Linien (weil gefiltert)")

# ğŸ–ï¸ Bild mit KÃ¶rperlinien zeichnen
bild = estimator_2d.process_image_with_annotation(
    image_path=file,                     # ğŸ–¼ï¸ Welches Bild?
    output_path="image_annotated_filtered.png",  # ğŸ’¾ Wo speichern?
    ignore_keypoints=DEFAULT_IGNORE_KEYPOINTS,   # ğŸš« Welche Punkte ignorieren?
    draw_bbox=True,                      # ğŸŸ© GrÃ¼ne Rahmen zeichnen?
    draw_keypoints=True,                 # ğŸ”´ Punkte zeichnen?
    keypoint_threshold=0.3               # ğŸ¯ Mindest-Genauigkeit
)
print("ğŸ’¾ Gespeichert: image_annotated_filtered.png")
print("   Ã–ffne die Datei um das Ergebnis zu sehen!")

# ===============================================
# ğŸ”„ SCHRITT 4: 2D â†’ 3D KONVERTIEREN (Magie!)
# ===============================================
print("\n" + "="*80)
print("ğŸª„ SCHRITT 4: Mache aus dem 2D-Bild ein 3D-Modell")
print("="*80)
print("ğŸ® Stell dir vor:")
print("   ğŸ–¼ï¸  2D-Foto â†’ ğŸª„ Magie â†’ ğŸ¯ 3D-Figur")
print("")
print("âš™ï¸  Verwendete Methode: geometric (mathematische SchÃ¤tzung)")
print("   Alternative: 'mmpose' (fortgeschrittene KI, wenn installiert)")

# ğŸ”„ Die eigentliche 2Dâ†’3D Konvertierung
results_3d = convert_2d_poses_to_3d(
    "poses_2d_filtered.json",        # ğŸ“ Eingabe: Unsere 2D-Daten
    "poses_3d_filtered.json",        # ğŸ“ Ausgabe: Werden 3D-Daten
    lifting_method='ai'       # ğŸ”§ Methode: geometric (Mathe) oder ai (KI)
)
print("âœ… 3D-Modelle erfolgreich erstellt!")

# ğŸ“Š Zeige Statistiken Ã¼ber die 3D-Daten
if len(results_3d) > 0:
    frame0 = results_3d[0]['combined_3d']  # ğŸ¯ Beste 3D-Ansicht
    print(f"\nğŸ“Š 3D-Ergebnis-Statistiken:")
    print(f"   ğŸ‘¥ Personen: {frame0['num_persons']}")
    print(f"   ğŸ”§ Methode: {frame0['method']}")
    print(f"   ğŸ¯ Genauigkeit: {frame0['confidence']:.1%}")
    
    # ğŸ” Zeige Tiefen-Informationen
    kpts_3d = np.array(frame0['keypoints_3d'])
    if len(kpts_3d) > 0 and frame0['num_persons'] > 0:
        z_coords = kpts_3d[0, :, 2]  # ğŸ“ Z-Koordinaten (Tiefe)
        z_valid = z_coords[z_coords != 0]  # ğŸš« Filtere 0-Werte
        if len(z_valid) > 0:
            print(f"   ğŸ“ Tiefenbereich: {z_valid.min():.2f} bis {z_valid.max():.2f}")
            print(f"   ğŸ“ Durchschnittliche Tiefe: {z_valid.mean():.2f}")

# ===============================================
# ğŸ¨ SCHRITT 5: 3D-MODELLE VISUALISIEREN
# ===============================================
print("\n" + "="*80)
print("ğŸ¨ SCHRITT 5: Zeige die 3D-Modelle an")
print("="*80)
print("ğŸ–¥ï¸  Jetzt kommt der coole Teil: Interaktive 3D-Grafik!")
print("")
print("ğŸ¯ Was gezeichnet wird:")
print("   - ğŸ‘¤ Korrekte Schulter-Linien (Nase â†’ Schultern)")
print("   - âœ‹ Handgelenke an richtiger Position (Punkte 91 & 112)")
print("   - ğŸš« KEINE Bein-Verbindungen")
print("   - ğŸ” Tiefe 5x vergrÃ¶ÃŸert fÃ¼r bessere Sichtbarkeit")

# ğŸ¨ 3D-Visualisierung erstellen
z_scale = 5.0  # ğŸ” Tiefe verstÃ¤rken (fÃ¼r bessere 3D-Wirkung)
print(f"\nâš™ï¸  Einstellungen:")
print(f"   - Tiefen-VerstÃ¤rkung: {z_scale}x")
print(f"   - HÃ¤nde anzeigen: Ja")
print(f"   - Gesicht anzeigen: Ja")

# ğŸ–¼ï¸ Erstelle und zeige 3D-Grafik
plot_3d_pose_from_json(
    "poses_3d_filtered.json",  # ğŸ“ Unsere 3D-Daten
    frame_idx=0,               # ğŸï¸ Erstes Bild
    view='combined_3d',        # ğŸ¯ Beste Ansicht
    output_path="image_3d_filtered.png",  # ğŸ’¾ Speichere Bild
    z_scale=z_scale,           # ğŸ” Tiefen-VerstÃ¤rkung
    show_plot=True,            # ğŸ‘€ Sofort anzeigen?
    show_hands=True,           # âœ‹ HÃ¤nde zeigen?
    show_face=True             # ğŸ˜€ Gesicht zeigen?
)
print("ğŸ’¾ Gespeichert: image_3d_filtered.png")

# ===============================================
# ğŸ‰ ZUSAMMENFASSUNG: WAS WURDE GEMACHT?
# ===============================================
print("\n" + "="*80)
print("ğŸ‰ FERTIG! Die komplette Pipeline wurde erfolgreich durchlaufen!")
print("="*80)

print("\nğŸ“ ALLE ERSTELLTEN DATEIEN:")
print("   1. ğŸ“„ poses_2d_filtered.json        - 2D-Daten (ohne Beine)")
print("   2. ğŸ–¼ï¸  image_annotated_filtered.png  - Bild mit KÃ¶rperlinien")
print("   3. ğŸ“„ poses_3d_filtered.json        - 3D-Modelle")
print("   4. ğŸ¨ image_3d_filtered.png         - 3D-Visualisierung")

print("\nâœ… ALLE KORREKTUREN WURDEN DURCHGEFÃœHRT:")
print("   ğŸ‘ƒ Nase:             Punkt 0 â†’ Punkt 53 (genauer)")
print("   âœ‹ Linkes Handgelenk: Punkt 9 â†’ Punkt 91 (genauer)")
print("   âœ‹ Rechtes Handgelenk: Punkt 10 â†’ Punkt 112 (genauer)")
print("   ğŸš« Beine/FÃ¼ÃŸe:       Punkte 13-22 gefiltert (unsichtbar)")
print("   ğŸ”— Schultern:        Korrekte Verbindungen (Naseâ†’Schultern)")

print("\nğŸ”§ EINSTELLUNGEN DIESES LAUFS:")
print(f"   - Tiefen-VerstÃ¤rkung: {z_scale}x")
print("   - Mindest-Genauigkeit 2D: 90%")
print("   - 3D-Methode: geometric (mathematisch)")
print("   - HÃ¤nde angezeigt: Ja")
print("   - Gesicht angezeigt: Ja")